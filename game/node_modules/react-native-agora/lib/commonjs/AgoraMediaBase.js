"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.VideoPixelFormat = exports.VideoModulePosition = exports.VideoFrameProcessMode = exports.VideoFrame = exports.VideoBufferType = exports.UserAudioSpectrumInfo = exports.RenderModeType = exports.RecorderState = exports.RecorderInfo = exports.RecorderErrorCode = exports.RawAudioFrameOpModeType = exports.PacketOptions = exports.MediaSourceType = exports.MediaRecorderStreamType = exports.MediaRecorderContainerFormat = exports.MediaRecorderConfiguration = exports.MediaPlayerSourceType = exports.ExternalVideoSourceType = exports.ExternalVideoFrame = exports.EglContextType = exports.ContentInspectType = exports.ContentInspectResult = exports.ContentInspectModule = exports.ContentInspectConfig = exports.BytesPerSample = exports.AudioSpectrumData = exports.AudioRoute = exports.AudioPcmFrame = exports.AudioParams = exports.AudioParameters = exports.AudioFrameType = exports.AudioFramePosition = exports.AudioFrame = exports.AudioEncodedFrameInfo = exports.AudioDualMonoMode = void 0;
require("./extension/AgoraMediaBaseExtension");
function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }
/**
 * The type of the audio route.
 */
let AudioRoute;
/**
 * @ignore
 */
exports.AudioRoute = AudioRoute;
(function (AudioRoute) {
  AudioRoute[AudioRoute["RouteDefault"] = -1] = "RouteDefault";
  AudioRoute[AudioRoute["RouteHeadset"] = 0] = "RouteHeadset";
  AudioRoute[AudioRoute["RouteEarpiece"] = 1] = "RouteEarpiece";
  AudioRoute[AudioRoute["RouteHeadsetnomic"] = 2] = "RouteHeadsetnomic";
  AudioRoute[AudioRoute["RouteSpeakerphone"] = 3] = "RouteSpeakerphone";
  AudioRoute[AudioRoute["RouteLoudspeaker"] = 4] = "RouteLoudspeaker";
  AudioRoute[AudioRoute["RouteHeadsetbluetooth"] = 5] = "RouteHeadsetbluetooth";
  AudioRoute[AudioRoute["RouteUsb"] = 6] = "RouteUsb";
  AudioRoute[AudioRoute["RouteHdmi"] = 7] = "RouteHdmi";
  AudioRoute[AudioRoute["RouteDisplayport"] = 8] = "RouteDisplayport";
  AudioRoute[AudioRoute["RouteAirplay"] = 9] = "RouteAirplay";
})(AudioRoute || (exports.AudioRoute = AudioRoute = {}));
let BytesPerSample;
/**
 * @ignore
 */
exports.BytesPerSample = BytesPerSample;
(function (BytesPerSample) {
  BytesPerSample[BytesPerSample["TwoBytesPerSample"] = 2] = "TwoBytesPerSample";
})(BytesPerSample || (exports.BytesPerSample = BytesPerSample = {}));
class AudioParameters {
  constructor() {
    _defineProperty(this, "sample_rate", void 0);
    _defineProperty(this, "channels", void 0);
    _defineProperty(this, "frames_per_buffer", void 0);
  }
}

/**
 * The use mode of the audio data.
 */
exports.AudioParameters = AudioParameters;
let RawAudioFrameOpModeType;
/**
 * Media source type.
 */
exports.RawAudioFrameOpModeType = RawAudioFrameOpModeType;
(function (RawAudioFrameOpModeType) {
  RawAudioFrameOpModeType[RawAudioFrameOpModeType["RawAudioFrameOpModeReadOnly"] = 0] = "RawAudioFrameOpModeReadOnly";
  RawAudioFrameOpModeType[RawAudioFrameOpModeType["RawAudioFrameOpModeReadWrite"] = 2] = "RawAudioFrameOpModeReadWrite";
})(RawAudioFrameOpModeType || (exports.RawAudioFrameOpModeType = RawAudioFrameOpModeType = {}));
let MediaSourceType;
/**
 * @ignore
 */
exports.MediaSourceType = MediaSourceType;
(function (MediaSourceType) {
  MediaSourceType[MediaSourceType["AudioPlayoutSource"] = 0] = "AudioPlayoutSource";
  MediaSourceType[MediaSourceType["AudioRecordingSource"] = 1] = "AudioRecordingSource";
  MediaSourceType[MediaSourceType["PrimaryCameraSource"] = 2] = "PrimaryCameraSource";
  MediaSourceType[MediaSourceType["SecondaryCameraSource"] = 3] = "SecondaryCameraSource";
  MediaSourceType[MediaSourceType["PrimaryScreenSource"] = 4] = "PrimaryScreenSource";
  MediaSourceType[MediaSourceType["SecondaryScreenSource"] = 5] = "SecondaryScreenSource";
  MediaSourceType[MediaSourceType["CustomVideoSource"] = 6] = "CustomVideoSource";
  MediaSourceType[MediaSourceType["MediaPlayerSource"] = 7] = "MediaPlayerSource";
  MediaSourceType[MediaSourceType["RtcImagePngSource"] = 8] = "RtcImagePngSource";
  MediaSourceType[MediaSourceType["RtcImageJpegSource"] = 9] = "RtcImageJpegSource";
  MediaSourceType[MediaSourceType["RtcImageGifSource"] = 10] = "RtcImageGifSource";
  MediaSourceType[MediaSourceType["RemoteVideoSource"] = 11] = "RemoteVideoSource";
  MediaSourceType[MediaSourceType["TranscodedVideoSource"] = 12] = "TranscodedVideoSource";
  MediaSourceType[MediaSourceType["UnknownMediaSource"] = 100] = "UnknownMediaSource";
})(MediaSourceType || (exports.MediaSourceType = MediaSourceType = {}));
let ContentInspectResult;
/**
 * The type of video content moderation module.
 */
exports.ContentInspectResult = ContentInspectResult;
(function (ContentInspectResult) {
  ContentInspectResult[ContentInspectResult["ContentInspectNeutral"] = 1] = "ContentInspectNeutral";
  ContentInspectResult[ContentInspectResult["ContentInspectSexy"] = 2] = "ContentInspectSexy";
  ContentInspectResult[ContentInspectResult["ContentInspectPorn"] = 3] = "ContentInspectPorn";
})(ContentInspectResult || (exports.ContentInspectResult = ContentInspectResult = {}));
let ContentInspectType;
/**
 * A structure used to configure the frequency of video screenshot and upload.ContentInspectModule
 */
exports.ContentInspectType = ContentInspectType;
(function (ContentInspectType) {
  ContentInspectType[ContentInspectType["ContentInspectInvalid"] = 0] = "ContentInspectInvalid";
  ContentInspectType[ContentInspectType["ContentInspectModeration"] = 1] = "ContentInspectModeration";
  ContentInspectType[ContentInspectType["ContentInspectSupervision"] = 2] = "ContentInspectSupervision";
})(ContentInspectType || (exports.ContentInspectType = ContentInspectType = {}));
class ContentInspectModule {
  constructor() {
    _defineProperty(this, "type", void 0);
    _defineProperty(this, "interval", void 0);
  }
}

/**
 * Configuration of video screenshot and upload.
 */
exports.ContentInspectModule = ContentInspectModule;
class ContentInspectConfig {
  constructor() {
    _defineProperty(this, "extraInfo", void 0);
    _defineProperty(this, "modules", void 0);
    _defineProperty(this, "moduleCount", void 0);
  }
}

/**
 * @ignore
 */
exports.ContentInspectConfig = ContentInspectConfig;
class PacketOptions {
  constructor() {
    _defineProperty(this, "timestamp", void 0);
    _defineProperty(this, "audioLevelIndication", void 0);
  }
}

/**
 * @ignore
 */
exports.PacketOptions = PacketOptions;
class AudioEncodedFrameInfo {
  constructor() {
    _defineProperty(this, "sendTs", void 0);
    _defineProperty(this, "codec", void 0);
  }
}

/**
 * The parameters of the audio frame in PCM format.
 */
exports.AudioEncodedFrameInfo = AudioEncodedFrameInfo;
class AudioPcmFrame {
  constructor() {
    _defineProperty(this, "capture_timestamp", void 0);
    _defineProperty(this, "samples_per_channel_", void 0);
    _defineProperty(this, "sample_rate_hz_", void 0);
    _defineProperty(this, "num_channels_", void 0);
    _defineProperty(this, "bytes_per_sample", void 0);
    _defineProperty(this, "data_", void 0);
  }
}

/**
 * The channel mode.
 */
exports.AudioPcmFrame = AudioPcmFrame;
let AudioDualMonoMode;
/**
 * The video pixel format.
 */
exports.AudioDualMonoMode = AudioDualMonoMode;
(function (AudioDualMonoMode) {
  AudioDualMonoMode[AudioDualMonoMode["AudioDualMonoStereo"] = 0] = "AudioDualMonoStereo";
  AudioDualMonoMode[AudioDualMonoMode["AudioDualMonoL"] = 1] = "AudioDualMonoL";
  AudioDualMonoMode[AudioDualMonoMode["AudioDualMonoR"] = 2] = "AudioDualMonoR";
  AudioDualMonoMode[AudioDualMonoMode["AudioDualMonoMix"] = 3] = "AudioDualMonoMix";
})(AudioDualMonoMode || (exports.AudioDualMonoMode = AudioDualMonoMode = {}));
let VideoPixelFormat;
/**
 * Video display modes.
 */
exports.VideoPixelFormat = VideoPixelFormat;
(function (VideoPixelFormat) {
  VideoPixelFormat[VideoPixelFormat["VideoPixelDefault"] = 0] = "VideoPixelDefault";
  VideoPixelFormat[VideoPixelFormat["VideoPixelI420"] = 1] = "VideoPixelI420";
  VideoPixelFormat[VideoPixelFormat["VideoPixelBgra"] = 2] = "VideoPixelBgra";
  VideoPixelFormat[VideoPixelFormat["VideoPixelNv21"] = 3] = "VideoPixelNv21";
  VideoPixelFormat[VideoPixelFormat["VideoPixelRgba"] = 4] = "VideoPixelRgba";
  VideoPixelFormat[VideoPixelFormat["VideoPixelNv12"] = 8] = "VideoPixelNv12";
  VideoPixelFormat[VideoPixelFormat["VideoTexture2d"] = 10] = "VideoTexture2d";
  VideoPixelFormat[VideoPixelFormat["VideoTextureOes"] = 11] = "VideoTextureOes";
  VideoPixelFormat[VideoPixelFormat["VideoCvpixelNv12"] = 12] = "VideoCvpixelNv12";
  VideoPixelFormat[VideoPixelFormat["VideoCvpixelI420"] = 13] = "VideoCvpixelI420";
  VideoPixelFormat[VideoPixelFormat["VideoCvpixelBgra"] = 14] = "VideoCvpixelBgra";
  VideoPixelFormat[VideoPixelFormat["VideoPixelI422"] = 16] = "VideoPixelI422";
})(VideoPixelFormat || (exports.VideoPixelFormat = VideoPixelFormat = {}));
let RenderModeType;
/**
 * @ignore
 */
exports.RenderModeType = RenderModeType;
(function (RenderModeType) {
  RenderModeType[RenderModeType["RenderModeHidden"] = 1] = "RenderModeHidden";
  RenderModeType[RenderModeType["RenderModeFit"] = 2] = "RenderModeFit";
  RenderModeType[RenderModeType["RenderModeAdaptive"] = 3] = "RenderModeAdaptive";
})(RenderModeType || (exports.RenderModeType = RenderModeType = {}));
let EglContextType;
/**
 * The video buffer type.
 */
exports.EglContextType = EglContextType;
(function (EglContextType) {
  EglContextType[EglContextType["EglContext10"] = 0] = "EglContext10";
  EglContextType[EglContextType["EglContext14"] = 1] = "EglContext14";
})(EglContextType || (exports.EglContextType = EglContextType = {}));
let VideoBufferType;
/**
 * The external video frame.
 */
exports.VideoBufferType = VideoBufferType;
(function (VideoBufferType) {
  VideoBufferType[VideoBufferType["VideoBufferRawData"] = 1] = "VideoBufferRawData";
  VideoBufferType[VideoBufferType["VideoBufferArray"] = 2] = "VideoBufferArray";
  VideoBufferType[VideoBufferType["VideoBufferTexture"] = 3] = "VideoBufferTexture";
})(VideoBufferType || (exports.VideoBufferType = VideoBufferType = {}));
class ExternalVideoFrame {
  constructor() {
    _defineProperty(this, "type", void 0);
    _defineProperty(this, "format", void 0);
    _defineProperty(this, "buffer", void 0);
    _defineProperty(this, "stride", void 0);
    _defineProperty(this, "height", void 0);
    _defineProperty(this, "cropLeft", void 0);
    _defineProperty(this, "cropTop", void 0);
    _defineProperty(this, "cropRight", void 0);
    _defineProperty(this, "cropBottom", void 0);
    _defineProperty(this, "rotation", void 0);
    _defineProperty(this, "timestamp", void 0);
    _defineProperty(this, "eglType", void 0);
    _defineProperty(this, "textureId", void 0);
    _defineProperty(this, "matrix", void 0);
    _defineProperty(this, "metadata_buffer", void 0);
    _defineProperty(this, "metadata_size", void 0);
  }
}

/**
 * Configurations of the video frame.
 * The video data format is YUV420. Note that the buffer provides a pointer to a pointer. This interface cannot modify the pointer of the buffer, but it can modify the content of the buffer.
 */
exports.ExternalVideoFrame = ExternalVideoFrame;
class VideoFrame {
  constructor() {
    _defineProperty(this, "type", void 0);
    _defineProperty(this, "width", void 0);
    _defineProperty(this, "height", void 0);
    _defineProperty(this, "yStride", void 0);
    _defineProperty(this, "uStride", void 0);
    _defineProperty(this, "vStride", void 0);
    _defineProperty(this, "yBuffer", void 0);
    _defineProperty(this, "uBuffer", void 0);
    _defineProperty(this, "vBuffer", void 0);
    _defineProperty(this, "rotation", void 0);
    _defineProperty(this, "renderTimeMs", void 0);
    _defineProperty(this, "avsync_type", void 0);
    _defineProperty(this, "metadata_buffer", void 0);
    _defineProperty(this, "metadata_size", void 0);
    _defineProperty(this, "textureId", void 0);
    _defineProperty(this, "matrix", void 0);
    _defineProperty(this, "alphaBuffer", void 0);
  }
}

/**
 * @ignore
 */
exports.VideoFrame = VideoFrame;
let MediaPlayerSourceType;
/**
 * The frame position of the video observer.
 */
exports.MediaPlayerSourceType = MediaPlayerSourceType;
(function (MediaPlayerSourceType) {
  MediaPlayerSourceType[MediaPlayerSourceType["MediaPlayerSourceDefault"] = 0] = "MediaPlayerSourceDefault";
  MediaPlayerSourceType[MediaPlayerSourceType["MediaPlayerSourceFullFeatured"] = 1] = "MediaPlayerSourceFullFeatured";
  MediaPlayerSourceType[MediaPlayerSourceType["MediaPlayerSourceSimple"] = 2] = "MediaPlayerSourceSimple";
})(MediaPlayerSourceType || (exports.MediaPlayerSourceType = MediaPlayerSourceType = {}));
let VideoModulePosition;
/**
 * Audio frame type.
 */
exports.VideoModulePosition = VideoModulePosition;
(function (VideoModulePosition) {
  VideoModulePosition[VideoModulePosition["PositionPostCapturer"] = 1] = "PositionPostCapturer";
  VideoModulePosition[VideoModulePosition["PositionPreRenderer"] = 2] = "PositionPreRenderer";
  VideoModulePosition[VideoModulePosition["PositionPreEncoder"] = 4] = "PositionPreEncoder";
})(VideoModulePosition || (exports.VideoModulePosition = VideoModulePosition = {}));
let AudioFrameType;
/**
 * Raw audio data.
 */
exports.AudioFrameType = AudioFrameType;
(function (AudioFrameType) {
  AudioFrameType[AudioFrameType["FrameTypePcm16"] = 0] = "FrameTypePcm16";
})(AudioFrameType || (exports.AudioFrameType = AudioFrameType = {}));
class AudioFrame {
  constructor() {
    _defineProperty(this, "type", void 0);
    _defineProperty(this, "samplesPerChannel", void 0);
    _defineProperty(this, "bytesPerSample", void 0);
    _defineProperty(this, "channels", void 0);
    _defineProperty(this, "samplesPerSec", void 0);
    _defineProperty(this, "buffer", void 0);
    _defineProperty(this, "renderTimeMs", void 0);
    _defineProperty(this, "avsync_type", void 0);
  }
}

/**
 * @ignore
 */
exports.AudioFrame = AudioFrame;
let AudioFramePosition;
/**
 * Audio data format.
 * The SDK sets the audio data format in the following callbacks according to AudioParams. onRecordAudioFrame onPlaybackAudioFrame onMixedAudioFrame The SDK calculates the sampling interval through the samplesPerCall, sampleRate, and channel parameters in AudioParams, and triggers the onRecordAudioFrame, onPlaybackAudioFrame, onMixedAudioFrame, and onEarMonitoringAudioFrame callbacks according to the sampling interval.Sample interval (sec) = samplePerCall/(sampleRate × channel).Ensure that the sample interval ≥ 0.01 (s).
 */
exports.AudioFramePosition = AudioFramePosition;
(function (AudioFramePosition) {
  AudioFramePosition[AudioFramePosition["AudioFramePositionNone"] = 0] = "AudioFramePositionNone";
  AudioFramePosition[AudioFramePosition["AudioFramePositionPlayback"] = 1] = "AudioFramePositionPlayback";
  AudioFramePosition[AudioFramePosition["AudioFramePositionRecord"] = 2] = "AudioFramePositionRecord";
  AudioFramePosition[AudioFramePosition["AudioFramePositionMixed"] = 4] = "AudioFramePositionMixed";
  AudioFramePosition[AudioFramePosition["AudioFramePositionBeforeMixing"] = 8] = "AudioFramePositionBeforeMixing";
  AudioFramePosition[AudioFramePosition["AudioFramePositionEarMonitoring"] = 16] = "AudioFramePositionEarMonitoring";
})(AudioFramePosition || (exports.AudioFramePosition = AudioFramePosition = {}));
class AudioParams {
  constructor() {
    _defineProperty(this, "sample_rate", void 0);
    _defineProperty(this, "channels", void 0);
    _defineProperty(this, "mode", void 0);
    _defineProperty(this, "samples_per_call", void 0);
  }
}

/**
 * The audio frame observer.
 */
exports.AudioParams = AudioParams;
/**
 * The audio spectrum data.
 */
class AudioSpectrumData {
  constructor() {
    _defineProperty(this, "audioSpectrumData", void 0);
    _defineProperty(this, "dataLength", void 0);
  }
}

/**
 * Audio spectrum information of the remote user.
 */
exports.AudioSpectrumData = AudioSpectrumData;
class UserAudioSpectrumInfo {
  constructor() {
    _defineProperty(this, "uid", void 0);
    _defineProperty(this, "spectrumData", void 0);
  }
}

/**
 * The audio spectrum observer.
 */
exports.UserAudioSpectrumInfo = UserAudioSpectrumInfo;
/**
 * The process mode of the video frame:
 */
let VideoFrameProcessMode;
/**
 * The IVideoFrameObserver class.
 */
exports.VideoFrameProcessMode = VideoFrameProcessMode;
(function (VideoFrameProcessMode) {
  VideoFrameProcessMode[VideoFrameProcessMode["ProcessModeReadOnly"] = 0] = "ProcessModeReadOnly";
  VideoFrameProcessMode[VideoFrameProcessMode["ProcessModeReadWrite"] = 1] = "ProcessModeReadWrite";
})(VideoFrameProcessMode || (exports.VideoFrameProcessMode = VideoFrameProcessMode = {}));
/**
 * The external video frame encoding type.
 */
let ExternalVideoSourceType;
/**
 * The format of the recording file.
 */
exports.ExternalVideoSourceType = ExternalVideoSourceType;
(function (ExternalVideoSourceType) {
  ExternalVideoSourceType[ExternalVideoSourceType["VideoFrame"] = 0] = "VideoFrame";
  ExternalVideoSourceType[ExternalVideoSourceType["EncodedVideoFrame"] = 1] = "EncodedVideoFrame";
})(ExternalVideoSourceType || (exports.ExternalVideoSourceType = ExternalVideoSourceType = {}));
let MediaRecorderContainerFormat;
/**
 * The recording content.
 */
exports.MediaRecorderContainerFormat = MediaRecorderContainerFormat;
(function (MediaRecorderContainerFormat) {
  MediaRecorderContainerFormat[MediaRecorderContainerFormat["FormatMp4"] = 1] = "FormatMp4";
})(MediaRecorderContainerFormat || (exports.MediaRecorderContainerFormat = MediaRecorderContainerFormat = {}));
let MediaRecorderStreamType;
/**
 * The current recording state.
 */
exports.MediaRecorderStreamType = MediaRecorderStreamType;
(function (MediaRecorderStreamType) {
  MediaRecorderStreamType[MediaRecorderStreamType["StreamTypeAudio"] = 1] = "StreamTypeAudio";
  MediaRecorderStreamType[MediaRecorderStreamType["StreamTypeVideo"] = 2] = "StreamTypeVideo";
  MediaRecorderStreamType[MediaRecorderStreamType["StreamTypeBoth"] = 3] = "StreamTypeBoth";
})(MediaRecorderStreamType || (exports.MediaRecorderStreamType = MediaRecorderStreamType = {}));
let RecorderState;
/**
 * The reason for the state change.
 */
exports.RecorderState = RecorderState;
(function (RecorderState) {
  RecorderState[RecorderState["RecorderStateError"] = -1] = "RecorderStateError";
  RecorderState[RecorderState["RecorderStateStart"] = 2] = "RecorderStateStart";
  RecorderState[RecorderState["RecorderStateStop"] = 3] = "RecorderStateStop";
})(RecorderState || (exports.RecorderState = RecorderState = {}));
let RecorderErrorCode;
/**
 * Configurations for the local audio and video recording.
 */
exports.RecorderErrorCode = RecorderErrorCode;
(function (RecorderErrorCode) {
  RecorderErrorCode[RecorderErrorCode["RecorderErrorNone"] = 0] = "RecorderErrorNone";
  RecorderErrorCode[RecorderErrorCode["RecorderErrorWriteFailed"] = 1] = "RecorderErrorWriteFailed";
  RecorderErrorCode[RecorderErrorCode["RecorderErrorNoStream"] = 2] = "RecorderErrorNoStream";
  RecorderErrorCode[RecorderErrorCode["RecorderErrorOverMaxDuration"] = 3] = "RecorderErrorOverMaxDuration";
  RecorderErrorCode[RecorderErrorCode["RecorderErrorConfigChanged"] = 4] = "RecorderErrorConfigChanged";
})(RecorderErrorCode || (exports.RecorderErrorCode = RecorderErrorCode = {}));
class MediaRecorderConfiguration {
  constructor() {
    _defineProperty(this, "storagePath", void 0);
    _defineProperty(this, "containerFormat", void 0);
    _defineProperty(this, "streamType", void 0);
    _defineProperty(this, "maxDurationMs", void 0);
    _defineProperty(this, "recorderInfoUpdateInterval", void 0);
  }
}

/**
 * The information about the file that is recorded.
 */
exports.MediaRecorderConfiguration = MediaRecorderConfiguration;
class RecorderInfo {
  constructor() {
    _defineProperty(this, "fileName", void 0);
    _defineProperty(this, "durationMs", void 0);
    _defineProperty(this, "fileSize", void 0);
  }
}

/**
 * The IMediaRecorderObserver class.
 */
exports.RecorderInfo = RecorderInfo;
//# sourceMappingURL=AgoraMediaBase.js.map